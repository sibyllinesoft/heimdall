# Tuning Service Configuration
environment: development
debug: true
log_level: INFO

# Training Configuration  
training:
  default_cv_folds: 5
  default_n_trials: 100
  default_optimize_hyperparams: true
  max_training_time_hours: 12
  embedding_dimension: 768
  
  # LightGBM default parameters
  lgb_defaults:
    objective: multiclass
    num_class: 3
    metric: multi_logloss
    boosting_type: gbdt
    num_leaves: 31
    learning_rate: 0.1
    feature_fraction: 0.8
    bagging_fraction: 0.8
    bagging_freq: 5
    verbose: -1

# Clustering Configuration
clustering:
  default_k_range_min: 3
  default_k_range_max: 15
  max_samples_for_optimization: 10000
  max_visualization_samples: 3000
  
  # Models to compute per-cluster quality scores for
  default_models:
    - "deepseek/deepseek-r1"
    - "qwen/qwen3-coder"
    - "openai/gpt-5"
    - "google/gemini-2.5-pro" 
    - "anthropic/claude-3.5-sonnet"

# Storage Configuration
storage:
  s3_bucket: "llm-router-artifacts"
  s3_region: "us-east-1"
  s3_endpoint_url: null  # Set for MinIO/LocalStack
  local_artifacts_dir: "./artifacts"
  max_artifacts_to_keep: 10

# API Configuration
api:
  host: "0.0.0.0"
  port: 8082
  max_concurrent_jobs: 3
  max_upload_size_mb: 100
  training_timeout_hours: 12